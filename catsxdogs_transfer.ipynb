{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catsxdogs_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cunhamaicon/catsxdogs/blob/master/catsxdogs_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "45ticwyzsuqg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning - Problema cats x dogs\n",
        "\n",
        "Implementação de rede convolucional usando transfer learning para diferenciação das categorias gato e cachorro.\n",
        "\n",
        " O banco de dados original se encontra [aqui](https://www.kaggle.com/c/dogs-vs-cats). Dentre essas imagens foram separadas 8000 imagens para treinamento e 2000 imagens para teste.\n",
        "\n",
        "Todo o código foi feito no Colab e pode ser compilado online em [https://colab.research.google.com](https://colab.research.google.com).\n",
        "\n",
        "\n",
        "** Autor: Maicon Henrique Cunha**\n",
        "\n",
        "Github: [https://github.com/cunhamaicon](https://github.com/cunhamaicon)"
      ]
    },
    {
      "metadata": {
        "id": "wvFs0wxIu7-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Procedimentos Iniciais"
      ]
    },
    {
      "metadata": {
        "id": "Ol_1ulM_u_Ln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apagar a pasta catsxdogs caso algum novo dado seja incluído na pasta:"
      ]
    },
    {
      "metadata": {
        "id": "0ybB41aUeRC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf catsxdogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwN6J1f0vUxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download da pasta:"
      ]
    },
    {
      "metadata": {
        "id": "u_eqqa_6eZT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cunhamaicon/catsxdogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3A7Y7GbvY2Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importação dos pacotes:"
      ]
    },
    {
      "metadata": {
        "id": "7q906nBeeHAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b19b971f-d058-468b-cda9-e56b86e7334e"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CbSaiWG3v2kB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN - Transfer learning:"
      ]
    },
    {
      "metadata": {
        "id": "ZGFvuzY2v-Sm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importando o modelo MobileNet que foi previamente treinado no ImageNet e descartando a última camada de neurônios:"
      ]
    },
    {
      "metadata": {
        "id": "1B3-bKjBwReh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=MobileNet(weights='imagenet',include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oO7FN2qEwgkf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Criando a saída do modelo MobileNet:"
      ]
    },
    {
      "metadata": {
        "id": "PwwGWkXWwi9G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=model.output\n",
        "x=GlobalAveragePooling2D()(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m34KAC6_wsPu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adicionando uma camada intermediária e a camada final:"
      ]
    },
    {
      "metadata": {
        "id": "f-g5WXZ2ebil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=Dense(50,activation='relu')(x)\n",
        "preds=Dense(1,activation='sigmoid')(x) \n",
        "model=Model(inputs=model.input,outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upU4C7VyxJN7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizando todas as camadas da nova rede criada usando o modelo MobileNetV2:"
      ]
    },
    {
      "metadata": {
        "id": "2VemyqKtfGdM",
        "colab_type": "code",
        "outputId": "f6661de6-fb92-454d-a96e-e833df7f394f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1601
        }
      },
      "cell_type": "code",
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_1\n",
            "88 dense_1\n",
            "89 dense_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MKJNIAKBybNY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo qual camada da rede será treinada. Nesse caso somente as duas últimas camadas adicionadas:"
      ]
    },
    {
      "metadata": {
        "id": "55aGsU4ufgJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:88]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[88:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDq6-50Jy1xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "ofmdrIHVy5j0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo o tamanho de cada batch:"
      ]
    },
    {
      "metadata": {
        "id": "nYPnSrmQhDSq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoUT3HQZzUm_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cada imagem do banco será apresentada a rede de uma forma diferente através do ImageDataGenerator:"
      ]
    },
    {
      "metadata": {
        "id": "aOePa8OAgOaf",
        "colab_type": "code",
        "outputId": "11869eef-79d2-424f-cc34-2cbe65006718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.4,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   height_shift_range=0.3,\n",
        "                                   width_shift_range=0.3,\n",
        "                                   rotation_range=50,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('catsxdogs/training_set',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('catsxdogs/test_set',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zN0NGzrc0QMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinamento"
      ]
    },
    {
      "metadata": {
        "id": "DlozFnpQ0WW2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definindo os parâmetros de compilação da rede:"
      ]
    },
    {
      "metadata": {
        "id": "lpeqcs5hgkd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr = 0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bb1x9_kz0i4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fazendo o treinamento da rede:"
      ]
    },
    {
      "metadata": {
        "id": "3tzvbgsYhkDK",
        "colab_type": "code",
        "outputId": "b17d2d00-af54-4e75-e9c8-7369c972ceaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=training_set,\n",
        "                   steps_per_epoch=8000/batch_size,\n",
        "                   epochs=10,\n",
        "                   validation_data = test_set,\n",
        "                   validation_steps = 2000/batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 107s 430ms/step - loss: 0.3477 - acc: 0.8405 - val_loss: 0.1113 - val_acc: 0.9570\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 102s 410ms/step - loss: 0.2045 - acc: 0.9169 - val_loss: 0.0796 - val_acc: 0.9685\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.1858 - acc: 0.9220 - val_loss: 0.0873 - val_acc: 0.9630\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 0.1789 - acc: 0.9254 - val_loss: 0.0640 - val_acc: 0.9750\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 104s 414ms/step - loss: 0.1645 - acc: 0.9290 - val_loss: 0.0708 - val_acc: 0.9715\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 0.1631 - acc: 0.9311 - val_loss: 0.0716 - val_acc: 0.9720\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 0.1593 - acc: 0.9361 - val_loss: 0.0715 - val_acc: 0.9710\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 103s 410ms/step - loss: 0.1601 - acc: 0.9321 - val_loss: 0.0605 - val_acc: 0.9775\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 0.1589 - acc: 0.9363 - val_loss: 0.0645 - val_acc: 0.9750\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.1547 - acc: 0.9351 - val_loss: 0.0523 - val_acc: 0.9810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bpE6bcT4DgXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Salvando o modelo para utilização futura:"
      ]
    },
    {
      "metadata": {
        "id": "9bKzjWBbnXaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('catsxdogs_mobilenet.h5')\n",
        "from google.colab import files\n",
        "files.download('catsxdogs_mobilenet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBLPwHxpC7MG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Previsão"
      ]
    },
    {
      "metadata": {
        "id": "IupvsIC2DHJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mostrando os arquivos da pasta single_prediction com imagens inéditas para a rede classificar:"
      ]
    },
    {
      "metadata": {
        "id": "-zi2res8DTo4",
        "colab_type": "code",
        "outputId": "e6717ce1-a566-4324-c496-03232c27ce43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "ls catsxdogs/single_prediction"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat_or_dog_1.jpg  chino1.jpg  floyd2.jpg  floyd4.jpg\n",
            "cat_or_dog_2.jpg  floyd1.jpg  floyd3.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjZPIcKiC-9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Escolhendo uma imagem da pasta single_prediction para fazer a previsão:"
      ]
    },
    {
      "metadata": {
        "id": "9qlK2kkPoMD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_image = image.load_img('catsxdogs/single_prediction/chino1.jpg', target_size = (224, 224))\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = test_image/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfF9Lf-XoRgH",
        "colab_type": "code",
        "outputId": "0e8fe44a-df89-46f9-e461-929aaff6724a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] > 0.5:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "    \n",
        "print(prediction)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}